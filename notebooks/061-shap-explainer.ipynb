{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68c37398",
   "metadata": {},
   "source": [
    "# SHAP Explainer (sLDA Features)\n",
    "\n",
    "SHAP values and feature importance interpretation for best model trained on sLDA features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d3976a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\javerkin\\Dropbox\\PhD\\Projects\\project-ds4pp-eth2025\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import shap\n",
    "\n",
    "# 1) Load model\n",
    "best_model = joblib.load(\"../models/best_slda_model.joblib\") # Changed to sLDA model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "872d2692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Best Model Summary\n",
      "------------------------------\n",
      "Model class: BayesianRidge\n",
      "\n",
      "Parameters:\n",
      "  â€¢ alpha_1: 1e-06\n",
      "  â€¢ alpha_2: 1e-06\n",
      "  â€¢ alpha_init: None\n",
      "  â€¢ compute_score: False\n",
      "  â€¢ copy_X: True\n",
      "  â€¢ fit_intercept: True\n",
      "  â€¢ lambda_1: 1e-06\n",
      "  â€¢ lambda_2: 1e-06\n",
      "  â€¢ lambda_init: None\n",
      "  â€¢ max_iter: 300\n",
      "  â€¢ tol: 0.001\n",
      "  â€¢ verbose: False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Summarize the best model\n",
    "# 1.1) Summarize best model type and parameters\n",
    "print(\"ðŸ” Best Model Summary\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"Model class: {type(best_model).__name__}\")\n",
    "print(\"\\nParameters:\")\n",
    "for name, value in best_model.get_params().items():\n",
    "    print(f\"  â€¢ {name}: {value}\")\n",
    "\n",
    "# If available, show feature importances\n",
    "if hasattr(best_model, \"feature_importances_\"):\n",
    "    print(\"\\nFeature importances (first 10):\")\n",
    "    import numpy as np\n",
    "    fi = best_model.feature_importances_\n",
    "    # Get feature names from X_test, which will be defined in the next cell\n",
    "    # This assumes X_test will be created before this cell is fully interpreted in a typical notebook execution flow\n",
    "    # For a direct script run, X_test would need to be defined earlier or passed here.\n",
    "    try:\n",
    "        feature_names = X_test.columns # Placeholder, X_test defined in next cell\n",
    "        sorted_indices = np.argsort(fi)[::-1]\n",
    "        for i in sorted_indices[:10]:\n",
    "            print(f\"  â€¢ {feature_names[i]}: {fi[i]:.4f}\")\n",
    "    except NameError: # Fallback if X_test is not yet defined (e.g. running cell by cell)\n",
    "        print(\"  (Feature names will be available after X_test is defined in the next cell)\")\n",
    "        for idx, imp in enumerate(fi[:10]):\n",
    "            print(f\"  {idx:2d}: {imp:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f37fc0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The passed model is not callable and cannot be analyzed directly with the given masker! Model: BayesianRidge()",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m X_test = df[features].iloc[split_idx:]\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# 3) Compute SHAP values\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m explainer = \u001b[43mshap\u001b[49m\u001b[43m.\u001b[49m\u001b[43mExplainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m shap_values = explainer(X_test)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# 4) Visualize\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\javerkin\\Dropbox\\PhD\\Projects\\project-ds4pp-eth2025\\.venv\\Lib\\site-packages\\shap\\explainers\\_explainer.py:206\u001b[39m, in \u001b[36mExplainer.__init__\u001b[39m\u001b[34m(self, model, masker, link, algorithm, output_names, feature_names, linearize_link, seed, **kwargs)\u001b[39m\n\u001b[32m    202\u001b[39m             algorithm = \u001b[33m\"\u001b[39m\u001b[33mpermutation\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    204\u001b[39m     \u001b[38;5;66;03m# if we get here then we don't know how to handle what was given to us\u001b[39;00m\n\u001b[32m    205\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    207\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mThe passed model is not callable and cannot be analyzed directly with the given masker! Model: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    208\u001b[39m             + \u001b[38;5;28mstr\u001b[39m(model)\n\u001b[32m    209\u001b[39m         )\n\u001b[32m    211\u001b[39m \u001b[38;5;66;03m# build the right subclass\u001b[39;00m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m algorithm == \u001b[33m\"\u001b[39m\u001b[33mexact\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[31mTypeError\u001b[39m: The passed model is not callable and cannot be analyzed directly with the given masker! Model: BayesianRidge()"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2) Load features and split into train/test (or load pre-split X_test)\n",
    "df = pd.read_csv(\"../data/processed/features_slda_monthly.csv\", parse_dates=[\"month\"]) # Changed to sLDA features\n",
    "# â€¦ re-create X_test as in your training script â€¦\n",
    "features = [c for c in df.columns if c.startswith(\"topic_\") or c.startswith(\"publication_\")] + [\"sentiment\"]\n",
    "split_idx = int(len(df) * 0.8)\n",
    "X_test = df[features].iloc[split_idx:]\n",
    "\n",
    "# 3) Compute SHAP values\n",
    "explainer = shap.Explainer(best_model)\n",
    "shap_values = explainer(X_test)\n",
    "\n",
    "# 4) Visualize\n",
    "shap.plots.beeswarm(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108744e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.beeswarm(shap_values, max_display=len(X_test.columns))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
